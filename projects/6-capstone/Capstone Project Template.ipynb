{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US immigration analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "Starting from a few different data sources I want to create a database where you can answers question about US immigration statistics.\n",
    "I will use I94 immigration dataset, a tataset containing temperature data from Kaggle and a US city demographic dataset from OpenSoft.\n",
    "I will import all data into Spark, clean it and prepare it for the destination database where you as a Data Analyst could answer your questions.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyjanitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession, GroupedData\n",
    "from pyspark.sql.functions import udf, col, year, month, dayofmonth\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType, IntegerType, DateType, DoubleType\n",
    "import datetime\n",
    "import janitor.spark\n",
    "\n",
    "import i94_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build spark session\n",
    "spark = SparkSession.builder \\\n",
    ".config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.1.0-s_2.11,org.postgresql:postgresql:9.4.1209\") \\\n",
    ".enableHiveSupport() \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare destination database params\n",
    "# For testing purposes I will use a local postgress database\n",
    "\n",
    "pg_mode = \"overwrite\"\n",
    "pg_url = \"jdbc:postgresql://postgres:5432/airflow\"\n",
    "pg_properties = {\"user\": \"airflow\",\"password\": \"airflow\",\"driver\": \"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "As a data engineer I need to prepare a database for our companies data analysts.\n",
    "They have a series of questions related to US immigration statistics.\n",
    "I will start by exploring the datasources, identify the columns, clean the data.\n",
    "Then I will structure the staging tables into our Fact and Dimmensions tables so the data is more accessible to business users questions.\n",
    "I will use Spark for this process and store the data into a Postgress database.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "- **I94 Immigration Data**: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. This is where the data comes from. There's a sample file so you can take a look at the data in csv format before reading it all in. You do not have to use the entire dataset, just use what you need to accomplish the goal you set at the beginning of the project.\n",
    "- **World Temperature Data**: This dataset came from Kaggle. You can read more about it here.\n",
    "- **U.S. City Demographic Data**: This data comes from OpenSoft. You can read more about it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "demographics_path = os.path.join(data_folder, \"us-cities-demographics.csv\")\n",
    "airport_codes_path = os.path.join(data_folder, \"airport-codes_csv.csv\")\n",
    "world_temperature_path = os.path.join(data_folder, \"GlobalLandTemperaturesByState.csv\")\n",
    "\n",
    "immigration_path = 'sas_data'\n",
    "valid_ports_codes = [x.upper() for x in list(i94_labels.i94prtl.keys())]\n",
    "valid_ports = i94_labels.i94prtl\n",
    "valid_states = i94_labels.i94addrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .load(demographics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_temperatures = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(world_temperature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from raw source or parsed parquet format\n",
    "if os.path.exists(immigration_path):\n",
    "    immigration_data = spark.read.parquet(immigration_path)\n",
    "else:\n",
    "    immigration_data = spark.read.format('com.github.saurfang.sas.spark') \\\n",
    "        .load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "    immigration_data.write.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic count: 2891\n",
      "World Temperatures count: 645675\n",
      "Immigration Data count: 2421760\n"
     ]
    }
   ],
   "source": [
    "# Performing cleaning tasks here\n",
    "print('Demographic count: %s' % demographics.count())\n",
    "print('World Temperatures count: %s' % world_temperatures.count())\n",
    "print('Immigration Data count: %s' % immigration_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49 valid states.\n"
     ]
    }
   ],
   "source": [
    "#Build a valid state df\n",
    "valid_state_codes = list(demographics.select(\"State Code\").distinct().toPandas()['State Code'])\n",
    "print('There are %s valid states.' % len(valid_state_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 660 ports.\n"
     ]
    }
   ],
   "source": [
    "print('There are %s ports.' % len(valid_ports_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues\n",
    "- must drop rows without: port, state_code and gender\n",
    "- states codes must be validated\n",
    "- drop rows from other countries than us\n",
    "- dates are in SAS format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SAS date to isoformat\n",
    "# SAS time starts from January 1st 1960\n",
    "def sas_to_isoformat(sas_time):\n",
    "    if sas_time:\n",
    "        return (datetime.datetime(1960, 1, 1).date() + datetime.timedelta(int(sas_time))).isoformat()\n",
    "    return None\n",
    "\n",
    "sas_to_isoformat_udf = udf(sas_to_isoformat, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert mdy date to isoformat\n",
    "def mdy_to_isoformat(mdy_date):\n",
    "    if mdy_date and len(mdy_date) == 8:\n",
    "        return (datetime.datetime.strptime(mdy_date, \"%m%d%Y\").date()).isoformat()\n",
    "    return None\n",
    "\n",
    "mdy_to_isoformat_udf = udf(mdy_to_isoformat, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \n",
    "clean_immigration_data = immigration_data.dropna(how=\"any\", subset=[\"i94port\", \"i94addr\", \"gender\"])\n",
    "\n",
    "# check states\n",
    "clean_immigration_data = clean_immigration_data.filter(~clean_immigration_data.i94addr.isin(valid_state_codes))\n",
    "\n",
    "# convert sas dates\n",
    "clean_immigration_data = clean_immigration_data.withColumn(\"arrdate\", sas_to_isoformat_udf(clean_immigration_data.arrdate).cast(DateType()))\n",
    "clean_immigration_data = clean_immigration_data.withColumn(\"depdate\", sas_to_isoformat_udf(clean_immigration_data.depdate).cast(DateType()))\n",
    "clean_immigration_data = clean_immigration_data.withColumn(\"dtaddto\", mdy_to_isoformat_udf(clean_immigration_data.dtaddto).cast(DateType()))\n",
    "\n",
    "# remote other states\n",
    "clean_immigration_data = clean_immigration_data.filter(clean_immigration_data.i94addr != 'other')\n",
    "\n",
    "# rename fields\n",
    "staging_immigration_data = clean_immigration_data.select(\n",
    "        col(\"cicid\").alias(\"id\").cast(IntegerType()), \n",
    "        col(\"i94yr\").alias(\"year\").cast(IntegerType()),\n",
    "        col(\"i94mon\").alias(\"month\").cast(IntegerType()),\n",
    "        col(\"arrdate\").alias(\"arrival_date\"),\n",
    "        col(\"depdate\").alias(\"depart_date\"),\n",
    "        col(\"dtaddto\").alias(\"allowed_date\"),\n",
    "        col(\"i94port\").alias(\"city_code\"),\n",
    "        col(\"i94addr\").alias(\"state_code\"),\n",
    "        col(\"i94bir\").alias(\"age\").cast(IntegerType()),\n",
    "        col(\"gender\").alias(\"gender\"),\n",
    "        col(\"i94visa\").alias(\"visa_type\").cast(IntegerType())\n",
    "    ).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkout immigration sample interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min(arrival_date)</th>\n",
       "      <th>max(arrival_date)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  min(arrival_date) max(arrival_date)\n",
       "0        2016-04-03        2016-04-28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_immigration_data.agg(F.min(\"arrival_date\"), F.max(\"arrival_date\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State Median Age Male Population  \\\n",
       "0     Silver Spring       Maryland       33.8           40601   \n",
       "1            Quincy  Massachusetts       41.0           44129   \n",
       "2            Hoover        Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga     California       34.5           88127   \n",
       "4            Newark     New Jersey       34.6          138040   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "\n",
       "  Average Household Size State Code                       Race  Count  \n",
       "0                    2.6         MD         Hispanic or Latino  25924  \n",
       "1                   2.39         MA                      White  58723  \n",
       "2                   2.58         AL                      Asian   4759  \n",
       "3                   3.18         CA  Black or African-American  24437  \n",
       "4                   2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column names to lower & underscore\n",
    "clean_demographics = demographics.clean_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_to_port_code(city):\n",
    "    for key, city_name in valid_ports.items():\n",
    "        if city.upper() in city_name.upper():\n",
    "            return key\n",
    "\n",
    "city_to_port_code_udf = udf(city_to_port_code, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_demographics = clean_demographics.withColumn(\"city_code\", city_to_port_code_udf(clean_demographics.city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_demographics = clean_demographics.dropna(how='any', subset=[\"city_code\", \"state\", \"race\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_demographics = clean_demographics \\\n",
    "    .withColumn(\"median_age\",col(\"median_age\").cast(DoubleType())) \\\n",
    "    .withColumn(\"male_population\",col(\"male_population\").cast(IntegerType())) \\\n",
    "    .withColumn(\"female_population\",col(\"female_population\").cast(IntegerType())) \\\n",
    "    .withColumn(\"total_population\",col(\"total_population\").cast(IntegerType())) \\\n",
    "    .withColumn(\"number_of_veterans\",col(\"number_of_veterans\").cast(IntegerType())) \\\n",
    "    .withColumn(\"foreign_born\",col(\"foreign_born\").cast(IntegerType())) \\\n",
    "    .withColumn(\"average_household_size\",col(\"average_household_size\").cast(DoubleType())) \\\n",
    "    .withColumn(\"count\",col(\"count\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "      <th>city_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "      <td>NEW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229</td>\n",
       "      <td>62432</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634</td>\n",
       "      <td>7517</td>\n",
       "      <td>2.40</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "      <td>PIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>34.1</td>\n",
       "      <td>741270</td>\n",
       "      <td>826172</td>\n",
       "      <td>1567442</td>\n",
       "      <td>61995</td>\n",
       "      <td>205339</td>\n",
       "      <td>2.61</td>\n",
       "      <td>PA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>122721</td>\n",
       "      <td>PHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>Florida</td>\n",
       "      <td>37.3</td>\n",
       "      <td>36850</td>\n",
       "      <td>37165</td>\n",
       "      <td>74015</td>\n",
       "      <td>4312</td>\n",
       "      <td>15365</td>\n",
       "      <td>2.45</td>\n",
       "      <td>FL</td>\n",
       "      <td>White</td>\n",
       "      <td>50169</td>\n",
       "      <td>FMY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laredo</td>\n",
       "      <td>Texas</td>\n",
       "      <td>28.8</td>\n",
       "      <td>124305</td>\n",
       "      <td>131484</td>\n",
       "      <td>255789</td>\n",
       "      <td>4921</td>\n",
       "      <td>68427</td>\n",
       "      <td>3.66</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1253</td>\n",
       "      <td>LCB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Allen</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>33.5</td>\n",
       "      <td>60626</td>\n",
       "      <td>59581</td>\n",
       "      <td>120207</td>\n",
       "      <td>5691</td>\n",
       "      <td>19652</td>\n",
       "      <td>2.67</td>\n",
       "      <td>PA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>22304</td>\n",
       "      <td>MCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New Haven</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>29.9</td>\n",
       "      <td>63765</td>\n",
       "      <td>66545</td>\n",
       "      <td>130310</td>\n",
       "      <td>2567</td>\n",
       "      <td>25871</td>\n",
       "      <td>2.48</td>\n",
       "      <td>CT</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>2205</td>\n",
       "      <td>NWH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Utah</td>\n",
       "      <td>32.1</td>\n",
       "      <td>98364</td>\n",
       "      <td>94296</td>\n",
       "      <td>192660</td>\n",
       "      <td>6829</td>\n",
       "      <td>32166</td>\n",
       "      <td>2.38</td>\n",
       "      <td>UT</td>\n",
       "      <td>Asian</td>\n",
       "      <td>13153</td>\n",
       "      <td>SLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>38.2</td>\n",
       "      <td>43048</td>\n",
       "      <td>45113</td>\n",
       "      <td>88161</td>\n",
       "      <td>10114</td>\n",
       "      <td>2829</td>\n",
       "      <td>2.72</td>\n",
       "      <td>VA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>39107</td>\n",
       "      <td>FOK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1958998</td>\n",
       "      <td>2012898</td>\n",
       "      <td>3971896</td>\n",
       "      <td>85417</td>\n",
       "      <td>1485425</td>\n",
       "      <td>2.86</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>2177650</td>\n",
       "      <td>LOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city         state  median_age  male_population  \\\n",
       "0          Newark    New Jersey        34.6           138040   \n",
       "1          Peoria      Illinois        33.1            56229   \n",
       "2    Philadelphia  Pennsylvania        34.1           741270   \n",
       "3      Fort Myers       Florida        37.3            36850   \n",
       "4          Laredo         Texas        28.8           124305   \n",
       "5           Allen  Pennsylvania        33.5            60626   \n",
       "6       New Haven   Connecticut        29.9            63765   \n",
       "7  Salt Lake City          Utah        32.1            98364   \n",
       "8         Suffolk      Virginia        38.2            43048   \n",
       "9     Los Angeles    California        35.0          1958998   \n",
       "\n",
       "   female_population  total_population  number_of_veterans  foreign_born  \\\n",
       "0             143873            281913                5829         86253   \n",
       "1              62432            118661                6634          7517   \n",
       "2             826172           1567442               61995        205339   \n",
       "3              37165             74015                4312         15365   \n",
       "4             131484            255789                4921         68427   \n",
       "5              59581            120207                5691         19652   \n",
       "6              66545            130310                2567         25871   \n",
       "7              94296            192660                6829         32166   \n",
       "8              45113             88161               10114          2829   \n",
       "9            2012898           3971896               85417       1485425   \n",
       "\n",
       "   average_household_size state_code                               race  \\\n",
       "0                    2.73         NJ                              White   \n",
       "1                    2.40         IL  American Indian and Alaska Native   \n",
       "2                    2.61         PA                              Asian   \n",
       "3                    2.45         FL                              White   \n",
       "4                    3.66         TX  American Indian and Alaska Native   \n",
       "5                    2.67         PA          Black or African-American   \n",
       "6                    2.48         CT  American Indian and Alaska Native   \n",
       "7                    2.38         UT                              Asian   \n",
       "8                    2.72         VA          Black or African-American   \n",
       "9                    2.86         CA                              White   \n",
       "\n",
       "     count city_code  \n",
       "0    76402       NEW  \n",
       "1     1343       PIA  \n",
       "2   122721       PHI  \n",
       "3    50169       FMY  \n",
       "4     1253       LCB  \n",
       "5    22304       MCA  \n",
       "6     2205       NWH  \n",
       "7    13153       SLC  \n",
       "8    39107       FOK  \n",
       "9  2177650       LOS  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_demographics.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_demographics.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean temperature data\n",
    "\n",
    "- Temperatures are not per day are actually averages per month.\n",
    "- We don't have Immigran's origin country so we will keep only temperatures from the US\n",
    "- We will remove any row without state or average_temperature\n",
    "- We will keep only more recent data because we don't have older immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1855-05-01</td>\n",
       "      <td>25.544</td>\n",
       "      <td>1.171</td>\n",
       "      <td>Acre</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1855-06-01</td>\n",
       "      <td>24.228</td>\n",
       "      <td>1.103</td>\n",
       "      <td>Acre</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1855-07-01</td>\n",
       "      <td>24.371</td>\n",
       "      <td>1.044</td>\n",
       "      <td>Acre</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1855-08-01</td>\n",
       "      <td>25.427</td>\n",
       "      <td>1.073</td>\n",
       "      <td>Acre</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1855-09-01</td>\n",
       "      <td>25.675</td>\n",
       "      <td>1.014</td>\n",
       "      <td>Acre</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty State Country\n",
       "0  1855-05-01             25.544                         1.171  Acre  Brazil\n",
       "1  1855-06-01             24.228                         1.103  Acre  Brazil\n",
       "2  1855-07-01             24.371                         1.044  Acre  Brazil\n",
       "3  1855-08-01             25.427                         1.073  Acre  Brazil\n",
       "4  1855-09-01             25.675                         1.014  Acre  Brazil"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_temperatures.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_code(state):\n",
    "    for key, s in valid_states.items():\n",
    "        print(state)\n",
    "        if state.upper() == s.upper():\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "get_state_code_udf = udf(get_state_code, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_world_temperatures = world_temperatures.clean_names(case_type='snake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check world temperatures sample interval. \n",
    "My data sample doesn't have overlaping intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min(dt)</th>\n",
       "      <th>max(dt)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>2013-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      min(dt)     max(dt)\n",
       "0  1743-11-01  2013-09-01"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_world_temperatures.agg(F.min(\"dt\"), F.max(\"dt\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_temperatures = clean_world_temperatures.filter(\n",
    "        (clean_world_temperatures.country == 'United States') &\n",
    "        (clean_world_temperatures.dt > '2000-01-01')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_temperatures = clean_temperatures \\\n",
    "    .withColumn('year', year(clean_world_temperatures.dt).cast(IntegerType())) \\\n",
    "    .withColumn('month', month(clean_world_temperatures.dt).cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_temperatures = clean_temperatures.withColumn(\"state_code\", get_state_code_udf(clean_world_temperatures[\"state\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_temperatures = clean_temperatures.dropna(how='any', subset=[\"state_code\", \"average_temperature\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_temperatures = clean_temperatures.select(\n",
    "        col(\"state\"), \n",
    "        col(\"state_code\"),\n",
    "        col(\"year\"), \n",
    "        col(\"month\"),\n",
    "        col(\"average_temperature\").cast(DoubleType()),\n",
    "        col(\"average_temperature_uncertainty\").cast(DoubleType()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7050"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_temperatures.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Staging tables\n",
    "\n",
    "https://dbdiagram.io/d/5ffafa2580d742080a35b116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Staging Tables](media/staging.png \"Staging Tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension and Facts tables\n",
    "\n",
    "https://dbdiagram.io/d/5ffae4d980d742080a35af8d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Star Schema](media/star_schema.png \"Star Schema.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "- Made a cleanup for each Staging tables\n",
    "- Will select all fields needed for Dimensions tables\n",
    "- Will select all fields needed for the Facts tables\n",
    "- Drop duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigrants_df = staging_immigration_data.select(\"id\", \"gender\", \"age\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31226"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrants_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df = clean_demographics.select(\n",
    "        \"city_code\", \"state_code\", \"city\", \"state\", \"median_age\",\n",
    "        \"male_population\", \"female_population\", \"total_population\", \n",
    "        \"number_of_veterans\", \"foreign_born\", \"average_household_size\", \"race\"\n",
    "    ).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df = staging_immigration_data.select(\"id\", \"arrival_date\", \"depart_date\", \"allowed_date\", \"state_code\", \"city_code\", \"visa_type\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31226"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_df = clean_temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7050"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatures_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write all data to a Postgress database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigrants_df.write.mode(\"overwrite\").jdbc(url=pg_url, table=\"immigrants\", mode=pg_mode, properties=pg_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_df.write.mode(\"overwrite\").jdbc(url=pg_url, table=\"cities\", mode=pg_mode, properties=pg_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.write.mode(\"overwrite\").jdbc(url=pg_url, table=\"visits\", mode=pg_mode, properties=pg_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures_df.write.mode(\"overwrite\").jdbc(url=pg_url, table=\"temperatures\", mode=pg_mode, properties=pg_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, gender: string, age: int]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "I will check the saved integrity\n",
    "- Dataframe counts should be the same as what is saved in the database\n",
    "- Some of the fields should be unique\n",
    "\n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "tables = ['immigrants', 'cities', 'visits', 'temperatures']\n",
    "\n",
    "for table in tables:\n",
    "    c = spark.read.jdbc(url=pg_url, table=\"temperatures\", properties=pg_properties).count()\n",
    "    if c == 0:\n",
    "        print('Table %s is empty' % table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check same counts between dataframes and database\n",
    "assert( immigrants_df.count() == spark.read.jdbc(url=pg_url, table=\"immigrants\", properties=pg_properties).count() )\n",
    "assert( cities_df.count() == spark.read.jdbc(url=pg_url, table=\"cities\", properties=pg_properties).count() )\n",
    "assert( visits_df.count() == spark.read.jdbc(url=pg_url, table=\"visits\", properties=pg_properties).count() )\n",
    "assert( temperatures_df.count() == spark.read.jdbc(url=pg_url, table=\"temperatures\", properties=pg_properties).count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert( immigrants_df.select(F.countDistinct(\"id\").alias('distinct_ids')).toPandas().distinct_ids[0] == immigrants_df.count() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "- Immigrant\n",
    "    - id\n",
    "    - age\n",
    "    - gender\n",
    "    \n",
    "- Cities\n",
    "    - city_code\n",
    "    - state_code\n",
    "    - city_name\n",
    "    - median_age\n",
    "    - male_population\n",
    "    - female_population\n",
    "    - total_pop\n",
    "    - number_of_veterans\n",
    "    - foreign_born\n",
    "    - average_household_size\n",
    "    - race\n",
    "\n",
    "- Temperatures\n",
    "    - state\n",
    "    - state_code\n",
    "    - year\n",
    "    - month\n",
    "    - avg_temperature\n",
    "    - average_temperature_uncertainty\n",
    "\n",
    "- Visits - Facts\n",
    "    - id\n",
    "    - year\n",
    "    - month\n",
    "    - origin\n",
    "    - state_code\n",
    "    - city_code\n",
    "    - date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* For this demo I choose Spark because we can use the same interface to read formats, write to many different formats or databases. Also Spark can handle large amounts of data so when our datasets will grow we can use the same tool to do the job.\n",
    "* The current example is made to be ran once and will overwrite the existing database.\n",
    "\n",
    "* Other usecases:\n",
    " * The data was increased by 100x.\n",
    "     - Spark will be able to handle this data but we will have to connect to a proper cluster, now it is used in local mode.\n",
    "     - The output database (Postgress) will probably not work, but we can use a Redshift cluster for the same purpose and they are compatible\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     - In order to accomodate daily jobs we will need to make few changes so we can batch import and we will probably some orchestration tool like Airflow.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "     - For the data to be accessible to multiple users we will probably need a bigger Redshift cluster and we will need to see the database usecases in order to optimize queries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
